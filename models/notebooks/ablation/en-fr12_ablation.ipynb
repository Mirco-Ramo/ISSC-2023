{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Ablation studies\n",
    "Feed the model with wrong/incomplete sentences.\n",
    "Look at model's ability to spot errors, mispells, measures"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import torch\n",
    "import warnings\n",
    "from tokenizers import Tokenizer\n",
    "\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "from IPython.display import SVG, display"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 0. Add packages to python path"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "b_paths = [os.path.abspath(os.path.join('..', '..', '..')), os.path.abspath(os.path.join('..', '..')), os.path.abspath(os.path.join('..', '..', 'scripts'))]\n",
    "for b_path in b_paths:\n",
    "    if b_path not in sys.path:\n",
    "        sys.path.append(b_path)\n",
    "\n",
    "BASE_DIR = Path(os.getcwd()).parent.parent.parent.resolve()\n",
    "%cd $BASE_DIR"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 1. Load model and test set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from models.scripts.generate_dataset import WordDatasetGenerator\n",
    "from models.scripts.transformer.printable_models import ExplainableTransformer\n",
    "from models.scripts.transformer.utils import preprocess_dataset, seed_all, strokes_to_svg, load_json_hypeparameters, pad_collate_fn\n",
    "from models.scripts.utils import Levenshtein_Normalized_distance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "VERSION = \"en-fr12\"\n",
    "SEED = 2021\n",
    "BATCH_SIZE = 256\n",
    "EXPR_MODE=\"all\"\n",
    "seed_all(SEED)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TOKENIZER_FILE = os.path.join(\"word_sources\",\"tokenizer-big_fr-normalized.json\")\n",
    "VOCAB = Tokenizer.from_file(TOKENIZER_FILE)\n",
    "\n",
    "BOS_IDX = VOCAB.token_to_id('<bos>')\n",
    "EOS_IDX = VOCAB.token_to_id('<eos>')\n",
    "PAD_IDX = VOCAB.token_to_id('<pad>')\n",
    "\n",
    "N_TOKENS = VOCAB.get_vocab_size() # len(VOCAB)\n",
    "print(f\"Number of Tokens: {N_TOKENS}\\n\")\n",
    "print(sorted(VOCAB.get_vocab()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "d_gen = WordDatasetGenerator(vocab = VOCAB, fname=\"words_stroke_fr_full\")\n",
    "test = d_gen.generate_from_cache(mode=\"test\")\n",
    "\n",
    "test_set = DataLoader(preprocess_dataset(test, VOCAB,  os.path.join(d_gen.fname+\"_fr\", \"test.pt\"), total_len=d_gen.get_learning_set_length(\"test\")), batch_size=BATCH_SIZE, shuffle=False, collate_fn=pad_collate_fn)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "hp = load_json_hypeparameters(VERSION)\n",
    "if \"vocab\" in hp:\n",
    "    hp.pop(\"vocab\")\n",
    "model = ExplainableTransformer(name=VERSION, vocab=VOCAB, **hp)\n",
    "model.count_parameters()\n",
    "print(f\"Conv trainable parameters: {sum(p.numel() for p in model.preencoder.parameters() if p.requires_grad):,}.\")\n",
    "print(f\"Encoder trainable parameters: {sum(p.numel() for p in model.encoder.parameters() if p.requires_grad):,}.\")\n",
    "print(f\"Decoder trainable parameters: {sum(p.numel() for p in model.decoder.parameters() if p.requires_grad):,}.\")\n",
    "model.load_best_version()\n",
    "model.to(model.device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Ablation studies"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ablation functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def find_sentence_ending_with_symbol(t_set, symbol, required_strokes=1):\n",
    "    id_symbol = VOCAB.token_to_id(symbol)\n",
    "    for x_batch, y_batch in t_set:   # iterate batches\n",
    "        #randomize elements in batch\n",
    "        idx = torch.randperm(x_batch.shape[0])\n",
    "        x_batch = x_batch[idx]\n",
    "        y_batch = y_batch[idx]\n",
    "        for ind in range(y_batch.shape[0]):  #iterate over sentences\n",
    "            x = x_batch[ind]\n",
    "            y = y_batch[ind]\n",
    "            try:\n",
    "                where_y = y.tolist().index(id_symbol)\n",
    "                where = -1\n",
    "                t = x[where, :]\n",
    "                eos_tensor = torch.zeros(x.size(-1)) + d_gen.eos_idx\n",
    "                pad_tensor = torch.zeros(x.size(-1)) + d_gen.padding_value\n",
    "                #find last element of the input (not padding or eos)\n",
    "                while torch.all(t.eq(eos_tensor)) or torch.all(t.eq(pad_tensor)):\n",
    "                    where -=1\n",
    "                    t = x[where, :]\n",
    "                # if last symbol requires more than 1 stroke, start replacing earlier\n",
    "                where -= (required_strokes-1)\n",
    "                where_x = x.size(0)+where\n",
    "                return x, y, where_x, where_y\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "    return None, None, None, None"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def replace_symbol(x, y, where_x, where_y):\n",
    "    eos_tensor = torch.zeros(x.size(-1)) + d_gen.eos_idx\n",
    "    pad_tensor = torch.zeros(x.size(-1)) + d_gen.padding_value\n",
    "    # replace first stroke of the symbol with eos_tensor\n",
    "    x[where_x, :] = eos_tensor\n",
    "    y[where_y] = EOS_IDX\n",
    "    # set to padding all successive ones\n",
    "    for j in range(where_x+1, x_pred.size(1)):\n",
    "        x[j, :] = pad_tensor\n",
    "    for j in range(where_y+1, len(y)):\n",
    "        y[j] = PAD_IDX\n",
    "    return x, y"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Remove final dot"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_pred, y_pred, position_x, position_y = find_sentence_ending_with_symbol(test_set, symbol=\".\")\n",
    "\n",
    "print(\"Original input:\")\n",
    "svg_str = strokes_to_svg(x_pred, {'height':100, 'width':100}, d_gen.padding_value, BOS_IDX, EOS_IDX)\n",
    "display(SVG(data = svg_str))\n",
    "\n",
    "\n",
    "gt = VOCAB.decode(y_pred.tolist()).replace(\" \", '').replace(\"Ġ\", \" \")\n",
    "gt_list = [i for i in y_pred.tolist() if i != 1]\n",
    "gt_length = len(gt)-2\n",
    "\n",
    "print(\"Ground truth => \", gt_list , '\\n')\n",
    "\n",
    "# Show ground truth and prediction along with the lengths of the words/glyphs\n",
    "print(f\"Ground Truth : {''.join(gt)} (len={gt_length})\")\n",
    "\n",
    "x_pred, y_pred = replace_symbol(x_pred, y_pred, position_x, position_y)\n",
    "\n",
    "print(\"Ablated input:\")\n",
    "svg_str = strokes_to_svg(x_pred, {'height':100, 'width':100}, d_gen.padding_value, BOS_IDX, EOS_IDX)\n",
    "display(SVG(data = svg_str))\n",
    "\n",
    "prediction, (cross_att, dec_att, enc_att), token_ids = model.predict(x_pred.unsqueeze(0).to(model.device))\n",
    "prediction = prediction.replace(\" \", '').replace(\"Ġ\", \" \")\n",
    "\n",
    "gt = VOCAB.decode(y_pred.tolist()).replace(\" \", '').replace(\"Ġ\", \" \")\n",
    "gt_list = [i for i in y_pred.tolist() if i != 1]\n",
    "gt_length = len(gt)-2\n",
    "\n",
    "print(\"Ablated Indices => \", gt_list , '\\n')\n",
    "\n",
    "# Show ground truth and prediction along with the lengths of the words/glyphs\n",
    "print(f\"Ablated new string: {''.join(gt)} (len={gt_length})\")\n",
    "print(f\" -- New Prediction: {prediction} (len={len(prediction)-2})\")\n",
    "\n",
    "#print(f\"Normalized Levenshtein distance is: {Levenshtein_Normalized_distance(gt, prediction)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def evaluate_ablation_metrics(symbol, req_strokes=1):\n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    TN = 0\n",
    "\n",
    "    for x_batch, y_batch in tqdm(test_set):\n",
    "        for ind in range(y_batch.shape[0]):  #iterate over sentences\n",
    "            x = x_batch[ind]\n",
    "            y = y_batch[ind]\n",
    "            #print(x.shape, y.shape)\n",
    "            x_f, y_f, pos_x, pos_y = find_sentence_ending_with_symbol([(x.unsqueeze(0), y.unsqueeze(0))], symbol, req_strokes)\n",
    "            if x_f is None:  # doesn't contain the symbol, it affects the precision\n",
    "                predict, _, _ = model.predict(x.unsqueeze(0).to(model.device))\n",
    "                predict = predict.replace(\" \", '').replace(\"Ġ\", \" \")\n",
    "                if predict.endswith(symbol):\n",
    "                    FP += 1\n",
    "                else:\n",
    "                    TN += 1\n",
    "            else:\n",
    "                x, y = replace_symbol(x_f, y_f, pos_x, pos_y)\n",
    "                predict, _, _ = model.predict(x.unsqueeze(0).to(model.device))\n",
    "                predict = predict.replace(\" \", '').replace(\"Ġ\", \" \")\n",
    "                if predict.endswith(symbol):\n",
    "                    TP += 1\n",
    "                else:\n",
    "                    FN += 1\n",
    "    return TP, TN, FP, FN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "SYMBOL=\".\"\n",
    "TP, TN, FP, FN = evaluate_ablation_metrics(SYMBOL)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"True positives: \",TP)\n",
    "print(\"True negatives: \",TN)\n",
    "print(\"False positives: \",FP)\n",
    "print(\"False negatives: \",FN)\n",
    "print()\n",
    "print(\"Accuracy: \", (TP+TN)/(TP+TN+FP+FN))\n",
    "print(\"Precision: \", TP/(TP+FP))\n",
    "print(\"Recall: \", TP/(TP+FN))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Remove final question_mark"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_pred, y_pred, position_x, position_y = find_sentence_ending_with_symbol(test_set, symbol=\"?\", required_strokes=2)\n",
    "\n",
    "print(\"Original input:\")\n",
    "svg_str = strokes_to_svg(x_pred, {'height':100, 'width':100}, d_gen.padding_value, BOS_IDX, EOS_IDX)\n",
    "display(SVG(data = svg_str))\n",
    "\n",
    "\n",
    "gt = VOCAB.decode(y_pred.tolist()).replace(\" \", '').replace(\"Ġ\", \" \")\n",
    "gt_list = [i for i in y_pred.tolist() if i != 1]\n",
    "gt_length = len(gt)-2\n",
    "\n",
    "print(\"Ground truth => \", gt_list , '\\n')\n",
    "\n",
    "# Show ground truth and prediction along with the lengths of the words/glyphs\n",
    "print(f\"Ground Truth : {''.join(gt)} (len={gt_length})\")\n",
    "\n",
    "x_pred, y_pred = replace_symbol(x_pred, y_pred, position_x, position_y)\n",
    "\n",
    "print(\"Ablated input:\")\n",
    "svg_str = strokes_to_svg(x_pred, {'height':100, 'width':100}, d_gen.padding_value, BOS_IDX, EOS_IDX)\n",
    "display(SVG(data = svg_str))\n",
    "\n",
    "prediction, _, _ = model.predict(x_pred.unsqueeze(0).to(model.device))\n",
    "prediction = prediction.replace(\" \", '').replace(\"Ġ\", \" \")\n",
    "\n",
    "gt = VOCAB.decode(y_pred.tolist()).replace(\" \", '').replace(\"Ġ\", \" \")\n",
    "gt_list = [i for i in y_pred.tolist() if i != 1]\n",
    "gt_length = len(gt)-2\n",
    "\n",
    "print(\"Ablated Indices => \", gt_list , '\\n')\n",
    "\n",
    "# Show ground truth and prediction along with the lengths of the words/glyphs\n",
    "print(f\"Ablated new string: {''.join(gt)} (len={gt_length})\")\n",
    "print(f\" -- New Prediction: {prediction} (len={len(prediction)-2})\")\n",
    "\n",
    "#print(f\"Normalized Levenshtein distance is: {Levenshtein_Normalized_distance(gt, prediction)}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "SYMBOL=\"?\"\n",
    "TP, TN, FP, FN = evaluate_ablation_metrics(SYMBOL, req_strokes=2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"True positives: \",TP)\n",
    "print(\"True negatives: \",TN)\n",
    "print(\"False positives: \",FP)\n",
    "print(\"False negatives: \",FN)\n",
    "print()\n",
    "print(\"Accuracy: \", (TP+TN)/(TP+TN+FP+FN))\n",
    "print(\"Precision: \", TP/(TP+FP))\n",
    "print(\"Recall: \", TP/(TP+FN))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Misspell"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from models.scripts.generate_dataset import WordGenerator\n",
    "\n",
    "misspelled_path = os.path.join(BASE_DIR, \"word_sources\", \"misspell_test\", \"french_misspelled.txt\")\n",
    "words = WordGenerator().generate_from_file(misspelled_path, words_only=False)\n",
    "\n",
    "d_gen = WordDatasetGenerator(vocab = VOCAB,\n",
    "                             expr_mode=EXPR_MODE,\n",
    "                             words=words,\n",
    "                             train_split=0.0,\n",
    "                             valid_split=0.0,\n",
    "                             extended_dataset=False,\n",
    "                             fname=\"misspelled_fr\")\n",
    "d_gen.generate()\n",
    "test = d_gen.generate_from_cache(mode=\"test\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "miss_en = DataLoader(preprocess_dataset(test, VOCAB,  os.path.join(d_gen.fname, \"test.pt\"), total_len=d_gen.get_learning_set_length(\"test\")), batch_size=BATCH_SIZE, shuffle=False, collate_fn=pad_collate_fn)\n",
    "x_pred, y_pred = next(iter(miss_en))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ind = random.choice(range(0, y_pred.shape[0]))\n",
    "print(\"Index:\", ind, \"\\n\")\n",
    "\n",
    "print(\"Ablated input:\")\n",
    "svg_str = strokes_to_svg(x_pred[ind], {'height':100, 'width':100}, d_gen.padding_value, BOS_IDX, EOS_IDX)\n",
    "display(SVG(data = svg_str))\n",
    "\n",
    "\n",
    "prediction, _ , _ = model.predict(x_pred[ind].unsqueeze(0).to(model.device))\n",
    "prediction = prediction.replace(\" \", '').replace(\"Ġ\", \" \")\n",
    "\n",
    "abl = VOCAB.decode(y_pred[ind].tolist()).replace(\" \", '').replace(\"Ġ\", \" \")\n",
    "abl_list = [i for i in y_pred[ind].tolist() if i != 1]\n",
    "abl_length = len(abl)-2\n",
    "\n",
    "print(\"Ablated input indices => \", abl_list , '\\n')\n",
    "\n",
    "# Show ground truth and prediction along with the lengths of the words/glyphs\n",
    "print(f\"Ablated input: {''.join(abl)} (len={abl_length})\")\n",
    "with open(os.path.join(BASE_DIR, \"word_sources\", \"misspell_test\", \"french_corrected.txt\"), \"r\", encoding=\"utf-8\") as gtf:\n",
    "    for i, line in enumerate(gtf):\n",
    "        if i == ind:\n",
    "            break\n",
    "\n",
    "gt = ' '+ WordGenerator().clean_sentence(line).replace(\"'\",\"\")\n",
    "print(f\"Corr sentence: {''.join(gt)} (len={len(gt)-1})\")\n",
    "\n",
    "print(f\"- Prediction : {''.join(prediction)} (len={len(prediction)-2})\")\n",
    "\n",
    "print()\n",
    "print(f\"- Gt - Ablated LA is: {Levenshtein_Normalized_distance(gt, abl)}\")\n",
    "print(f\"Gt -Prediction LA is: {Levenshtein_Normalized_distance(gt, prediction)}\")\n",
    "print(f\"Ablated - Pred LA is: {Levenshtein_Normalized_distance(abl, prediction)}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def compute_correction_metrics(t_set, corr_path):\n",
    "    gt_abl_LD = 0\n",
    "    gt_pred_LD = 0\n",
    "    abl_pred_LD = 0\n",
    "    with open(corr_path, \"r\", encoding=\"utf-8\") as gtf:\n",
    "        for b_x, b_y in t_set:\n",
    "            b_x = b_x.to(model.device)\n",
    "            b_y = b_y.to(model.device)\n",
    "            assert len(b_x) == len(b_y), \"Mismatch in test dimensions\"\n",
    "            for i, (x,y) in enumerate(zip(b_x, b_y), start=1):\n",
    "                prediction, _ , _ = model.predict(x.unsqueeze(0).to(model.device))\n",
    "                prediction = prediction.replace(\" \", '').replace(\"Ġ\", \" \")\n",
    "                ablation = VOCAB.decode(y.tolist()).replace(\" \", '').replace(\"Ġ\", \" \")\n",
    "                gt = ' '+ WordGenerator().clean_sentence(gtf.readline()).replace(\"'\",\"\")\n",
    "\n",
    "                gt_abl = Levenshtein_Normalized_distance(gt, ablation)\n",
    "                gt_pred = Levenshtein_Normalized_distance(gt, prediction)\n",
    "                abl_pred = Levenshtein_Normalized_distance(ablation, prediction)\n",
    "\n",
    "                gt_abl_LD = gt_abl_LD + ((gt_abl - gt_abl_LD) / i)\n",
    "                gt_pred_LD = gt_pred_LD + ((gt_pred - gt_pred_LD) / i)\n",
    "                abl_pred_LD = abl_pred_LD + ((abl_pred - abl_pred_LD) / i)\n",
    "\n",
    "    return 1-gt_abl_LD, 1-gt_pred_LD, 1-abl_pred_LD"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "gt_abl_LA, gt_pred_LA, abl_pred_LA = compute_correction_metrics(miss_en, os.path.join(BASE_DIR, \"word_sources\", \"misspell_test\", \"french_corrected.txt\"))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import math\n",
    "print(f\"Similarity between ground truth and ablated input is:  {gt_abl_LA} ({round(gt_abl_LA, 4)*100}%).\")\n",
    "print(f\"This means that we artificially added a degree of error in the db of {1-gt_abl_LA} ({round((1-gt_abl_LA), 4)*100}%).\")\n",
    "print()\n",
    "print(f\"Model's predictions when input is ablated are on average accurate at {gt_pred_LA} ({round(gt_pred_LA, 4)*100}%).\")\n",
    "print(f\"So the total error of the model is {1-gt_pred_LA} ({round((1-gt_pred_LA), 4)*100}%).\")\n",
    "print()\n",
    "print(f\"Model's degree of similarity with the ablated input is {abl_pred_LA} ({round(abl_pred_LA, 4)*100}%).\")\n",
    "print()\n",
    "s = ((1-gt_pred_LA) +  (1-gt_abl_LA) + (1- abl_pred_LA))/2\n",
    "Area = math.sqrt(s*(s-1+gt_abl_LA)*(s-1+gt_pred_LA)*(s-1+abl_pred_LA))\n",
    "only_pred_error = 2*Area/(1-gt_abl_LA)\n",
    "abl_and_pred_error = math.sqrt((1-gt_pred_LA)**2-(only_pred_error**2))\n",
    "abl_non_pred_error = (1-gt_abl_LA)-abl_and_pred_error\n",
    "\n",
    "if gt_pred_LA > gt_abl_LA:\n",
    "    print(f\"This means that on average the model learned to recognize incorrect input, reducing the total amount of error to {1-gt_pred_LA}. {gt_pred_LA-gt_abl_LA} lower than the one that we artificially introduced.\")\n",
    "\n",
    "else:\n",
    "    print(f\"The model is actually adding more error than the one it is able to recognize and correct.\")\n",
    "print()\n",
    "print(f\"{only_pred_error} ({round(only_pred_error, 4)*100}%) is the additional recognition error introduced by the model.\")\n",
    "print(f\"{abl_and_pred_error} ({round(abl_and_pred_error, 4)*100}%) is the error artificially introduced through ablation and that was resembled by the model.\")\n",
    "print(f\"{abl_non_pred_error} ({round(abl_non_pred_error, 4)*100}%) is the error that was artificially introduced but it was corrected by the model.\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
