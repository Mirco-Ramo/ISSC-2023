{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# conv3 training"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import warnings\n",
    "from tokenizers import Tokenizer\n",
    "from tokenizers.models import BPE\n",
    "from tokenizers import normalizers\n",
    "from tokenizers import pre_tokenizers\n",
    "from tokenizers.normalizers import NFD, StripAccents\n",
    "from tokenizers.pre_tokenizers import ByteLevel, Digits\n",
    "from tokenizers.trainers import BpeTrainer\n",
    "import torch.nn as nn\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import torch as torch\n",
    "from IPython.display import SVG, display\n",
    "\n",
    "from torch.utils.data import DataLoader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Enable Hot Reload"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Edit Python path\n",
    "Add the `models` directory to Python's `path`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "b_paths = [os.path.abspath(os.path.join('..', '..', '..')), os.path.abspath(os.path.join('..', '..')), os.path.abspath(os.path.join('..', '..', 'scripts'))]\n",
    "for b_path in b_paths:\n",
    "    if b_path not in sys.path:\n",
    "        sys.path.append(b_path)\n",
    "\n",
    "BASE_DIR = Path(os.getcwd()).parent.parent.parent.resolve()\n",
    "%cd $BASE_DIR"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ignore Warnings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Import Helpers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from models.scripts.transformer.PreEncoders import Conv2DTransformer\n",
    "from models.scripts.transformer.utils import strokes_to_svg, preprocess_dataset, seed_all, pad_collate_fn, tensor_to_word\n",
    "from models.scripts.generate_dataset import WordDatasetGenerator, WordGenerator"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Configuration Settings"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "VERSION = \"conv3\"\n",
    "SEED = 2021\n",
    "BATCH_SIZE = 256\n",
    "EXPR_MODE = 'all'"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "seed_all(SEED) # Reproducibility"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create Vocabulary and dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TOKENIZER_FILE = os.path.join(\"word_sources\",\"tokenizer-news-normalized.json\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "use_cache = True\n",
    "\n",
    "if use_cache: # Generate from cache file\n",
    "    VOCAB = Tokenizer.from_file(TOKENIZER_FILE)\n",
    "\n",
    "    d_gen = WordDatasetGenerator(vocab = VOCAB,\n",
    "                                 expr_mode=EXPR_MODE,\n",
    "                                 fname=\"words_stroke_100_155805\")\n",
    "    train, valid, test = d_gen.generate_from_cache()\n",
    "\n",
    "else: # Generate from scratch and cache (if regenerated, results could change)\n",
    "    news_commentary_path = os.path.join(BASE_DIR, \"word_sources\", \"news-commentary-v14.en\")\n",
    "    words = WordGenerator().generate_from_file(news_commentary_path, words_only=False)\n",
    "\n",
    "    VOCAB = Tokenizer(BPE())\n",
    "    VOCAB.normalizer = normalizers.Sequence([NFD(), StripAccents()])\n",
    "    VOCAB.pre_tokenizer = pre_tokenizers.Sequence([Digits(), ByteLevel()])\n",
    "    # Train it\n",
    "    trainer = BpeTrainer(\n",
    "        vocab_size=2000,\n",
    "        min_frequency=25,\n",
    "        show_progress=True,\n",
    "        special_tokens=['<unk>', '<pad>', '<bos>', '<eos>']\n",
    "    )\n",
    "    VOCAB.train_from_iterator(words, trainer)\n",
    "    # Save the tokenizer model\n",
    "    VOCAB.save(f\"{TOKENIZER_FILE}_new\")\n",
    "    BRUSH_SPLIT=0.15\n",
    "    d_gen = WordDatasetGenerator(vocab = VOCAB,\n",
    "                                 expr_mode=EXPR_MODE,\n",
    "                                 words=words[:int(len(words)*(1-BRUSH_SPLIT))],\n",
    "                                 extended_dataset=False)\n",
    "    d_gen.generate()\n",
    "    d_gen.add_training_words(words[int(len(words)*(1-BRUSH_SPLIT)):])\n",
    "    train, valid, test = d_gen.generate_from_cache()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualize tokenizer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(VOCAB)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(sorted(VOCAB.get_vocab()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(VOCAB.token_to_id(\"<bos>\"))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "N_TOKENS = VOCAB.get_vocab_size() # len(VOCAB)\n",
    "print(f\"Number of Tokens: {N_TOKENS}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create Dataset for PyTorch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_set = DataLoader(preprocess_dataset(train, VOCAB,  os.path.join(d_gen.fname+\"-bpe\", \"train.pt\"), total_len=d_gen.get_learning_set_length(\"train\")), batch_size=BATCH_SIZE, shuffle=True, collate_fn=pad_collate_fn)\n",
    "valid_set = DataLoader(preprocess_dataset(valid, VOCAB,  os.path.join(d_gen.fname+\"-bpe\", \"valid.pt\"), total_len=d_gen.get_learning_set_length(\"valid\")), batch_size=BATCH_SIZE, shuffle=False, collate_fn=pad_collate_fn)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Inspect Generated Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get random index\n",
    "x_dummy, y_dummy = next(iter(valid_set)) # Create dummy for visualization\n",
    "ind = random.choice(range(y_dummy.shape[0]))\n",
    "print(\"Index:\", ind)\n",
    "\n",
    "print()\n",
    "print(\"X Shape:\", x_dummy[ind].shape)\n",
    "# Show actual expr for first tensor\n",
    "print(\"Y Shape:\", y_dummy[ind].shape)\n",
    "print()\n",
    "print(\"Label:\", VOCAB.decode(y_dummy[ind].tolist(), False))\n",
    "\n",
    "# Get length of subplot depending on granularity (exclude bos/eos for strokes)\n",
    "svg_str = strokes_to_svg(x_dummy[ind], {'height':100, 'width':100}, d_gen.padding_value, VOCAB.token_to_id('<bos>'), VOCAB.token_to_id('<eos>'))\n",
    "display(SVG(data = svg_str))\n",
    "\n",
    "\n",
    "print()\n",
    "print(f'X[{ind}]:', x_dummy[ind])\n",
    "print()\n",
    "\n",
    "eos_tensor = torch.zeros(x_dummy[ind].size(-1)) + d_gen.eos_idx\n",
    "\n",
    "\n",
    "for i, row in enumerate(x_dummy[ind]):\n",
    "    if torch.all(row.eq(eos_tensor)):\n",
    "        print(\"EOS is in position:\", i)\n",
    "        break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model Hyper-parameters/Create Transformer Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model= Conv2DTransformer(VERSION, VOCAB, n_tokens=N_TOKENS, encoder_name='bpe2', decoder_name='bpe2', n_conv_layers=4)\n",
    "model.save_hyperparameters_to_json()\n",
    "model.count_parameters()\n",
    "print(f\"Convolution trainable parameters: {sum(p.numel() for p in model.preencoder.parameters() if p.requires_grad):,}.\")\n",
    "print(f\"Encoder trainable parameters: {sum(p.numel() for p in model.encoder.parameters() if p.requires_grad):,}.\")\n",
    "print(f\"Decoder trainable parameters: {sum(p.numel() for p in model.decoder.parameters() if p.requires_grad):,}.\")\n",
    "print(\"\\n\\n\\n\", model)\n",
    "model.to(model.device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Training conv layers and caching"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "LEARNING_RATE = 5e-4\n",
    "criterion = nn.CrossEntropyLoss(ignore_index=VOCAB.token_to_id('<pad>'))\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=40, gamma=0.5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.train_loop(resume=False,\n",
    "                 train_set=train_set,\n",
    "                 valid_set=valid_set,\n",
    "                 optimizer=optimizer,\n",
    "                 scheduler=scheduler,\n",
    "                 n_epochs=120)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot Training Logs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.plot_training()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Fine tuning the whole Transformer"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.load_best_version()\n",
    "model.encoder.requires_grad_(True)\n",
    "model.decoder.requires_grad_(True)\n",
    "model.name += \"_ft\"\n",
    "model.save_hyperparameters_to_json()\n",
    "model.bm_path = model.bm_path[:-3] + \"_ft\" + \".pt\"\n",
    "model.log_path = model.log_path[:-4] + \"_ft\" + \".log\"\n",
    "\n",
    "LEARNING_RATE = 1.5e-4\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=300, gamma=0.5)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.train_loop(resume=False,\n",
    "                 train_set=train_set,\n",
    "                 valid_set=valid_set,\n",
    "                 optimizer=optimizer,\n",
    "                 scheduler=scheduler,\n",
    "                 n_epochs=4000)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Plot Training  Logs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "model.plot_training()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
